{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXSVCIhz_bJ2"
      },
      "source": [
        "# Лабораторная работа №5\n",
        "\n",
        "**Многослойный перцептрон в pytorch**\n",
        "\n",
        "---\n",
        "\n",
        "**Впишите в эту ячейку ваши ФИО, группу и вариант**.\n",
        "\n",
        "ФИО: Сильченко Алексей Евгеньевич   \n",
        "\n",
        "Группа: 201-361\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQQXVD6rWsZH"
      },
      "source": [
        "## Работа с тензорами\n",
        "\n",
        "**Совет по работе**\n",
        "\n",
        "Создавайте отдельные ячейки для ваших экспериментов. Пробуйте создавать небольшие тензоры и экспериментировать с ними, чтобы понять, как работает та или иная функция и какие размерности данных вам требуются.\n",
        "\n",
        "Когда дойдете до цикла обучения сначала пробуйте работать с одной эпохой и ограниченным набором пакетов данных, чтобы меньше времени ожидать до обнаружения ошибки."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmYJrB2Z_n_g"
      },
      "source": [
        "Создайте тензор a из `list(range(9))`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "dD5G9vbe-5Be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "a = torch.tensor(list(range(9)))\n",
        "print(a)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R26toMZSVTay"
      },
      "source": [
        "**Каковы его размеры (`size`), сдвиг (`storage_offset`) и шаг (`stride`)?**\n",
        "\n",
        "Ваш ответ:\n",
        "- `size` = 9 \n",
        "- `storage_offset` = 0 - указывает на индекс с которого начинаются данные в тензоре, в данном случае равен 0, т.к. данные начинаются с 1-го элемента\n",
        "- `stride` = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6jEV7Kf_4lY"
      },
      "source": [
        "Создайте новый тензор b размерностью 3 на 3, используя метод `view` на тензоре a."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "RTL58iBKAQGz"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0, 1, 2],\n",
            "        [3, 4, 5],\n",
            "        [6, 7, 8]])\n"
          ]
        }
      ],
      "source": [
        "b = a.view(3, 3)\n",
        "print(b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tADzm6ckVie5"
      },
      "source": [
        "**Что делает view?**\n",
        "\n",
        "Ваш ответ: Метод `view` в PyTorch используется для изменения формы тензора без изменения его данных. Он возвращает новый тензор, который имеет указанную форму, но использует те же данные, что и исходный тензор, так что изменения в одном тензоре отражаются в другом. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVm_FySuV0wR"
      },
      "source": [
        "Создайте тензор c, который содержит только последнюю колонку тензора b, используя срезы."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "mD_T69LEV1FU"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([2, 5, 8])\n"
          ]
        }
      ],
      "source": [
        "c = b[:, -1]\n",
        "print(c)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxv_BqYeWSyu"
      },
      "source": [
        "Измените последний элемент в тензоре c."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Lm9Fz2PbWa5i"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Тензор c:\n",
            "tensor([ 2,  5, 99])\n",
            "Тензор b:\n",
            "tensor([[ 0,  1,  2],\n",
            "        [ 3,  4,  5],\n",
            "        [ 6,  7, 99]])\n"
          ]
        }
      ],
      "source": [
        "c[-1] = 99\n",
        "print(\"Тензор c:\")\n",
        "print(c)\n",
        "print(\"Тензор b:\")\n",
        "print(b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8hMn5CKWfkv"
      },
      "source": [
        "**Изменился ли при этом тензор a?**\n",
        "\n",
        "Ваш ответ: Да, тензор `a` также изменился. Это связано с тем, что в PyTorch операция `view` создаёт новый тензор, который является представлением исходного тензора, не копируя данные. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKUCdApxKqpV"
      },
      "source": [
        "## Чтение данных и dataset\n",
        "\n",
        "Из встроенных датасетов torchvision загрузите тестовую и обучающую выборки из MNIST, указав преобразование для изображений используя ToTensor()."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "xXIylPhVKy22"
      },
      "outputs": [],
      "source": [
        "from torchvision import datasets #библиотека с утилитами для компьютерного зрения\n",
        "from torchvision.transforms import ToTensor #библиотека для преобразования изображений в тензоры\n",
        "\n",
        "#обучающий набор данных\n",
        "train_set = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "# Создание тестового набора данных\n",
        "test_set = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXrw-DolX5I4"
      },
      "source": [
        "Датасеты позволяют получить общее количество объектов с помощью функции `len`, также - объект с классом по индексу. В атрибуте `classes` хранятся ярлыки классов."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "jPyS_M2MQIkp"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "60000 10000 torch.Size([1, 28, 28]) 10 ['0 - zero', '1 - one', '2 - two', '3 - three', '4 - four', '5 - five', '6 - six', '7 - seven', '8 - eight', '9 - nine']\n"
          ]
        }
      ],
      "source": [
        "# Длина обучающего и тестового наборов\n",
        "train_samples_len = len(train_set)\n",
        "test_samples_len = len(test_set)\n",
        "\n",
        "# Получаем форму первого изображения в обучающем наборе\n",
        "image_shape = train_set[0][0].shape\n",
        "\n",
        "# Количество классов и их ярлыки\n",
        "classes_len = len(train_set.classes)\n",
        "classes_labels = train_set.classes\n",
        "\n",
        "print(train_samples_len, test_samples_len, image_shape, classes_len, classes_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yoIxKt9KzNA"
      },
      "source": [
        "## Создание dataloader\n",
        "\n",
        "Данные при обучении модели редко передаются по одному образцу или все разом, обычно образцы объединяются в пакеты (batches) и уже они передаются на вход модели.\n",
        "\n",
        "Размер пакета (batch size) часто выбирается как $2^n$ (16, 32, 64, 128) и часто это зависит от доступной памяти.\n",
        "\n",
        "Загрузчики данных будут использоваться при обучении и тестировании модели и когда все пакеты были перебраны в датасете, это считается одной эпохой обучения. Чтобы между эпохами модель на обучалась на одинаковых пакетах их перемешивают (shuffle)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "mkWHD_HlK2oX"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "b33-Y41eQtEW"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_set, 32, shuffle=True)\n",
        "\n",
        "# Создание загрузчика данных для тестового набора\n",
        "# Здесь shuffle=False, так как перемешивание не требуется\n",
        "test_loader = DataLoader(test_set, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-MdcGx_Zccw"
      },
      "source": [
        "**Что означает число 32 в примере для train_loader?**\n",
        "\n",
        "Ваш ответ: Это количество образцов данных, которые будут сгруппированы в один пакет и переданы на обработку модели за один раз во время обучения.\n",
        "\n",
        "**Какая размерность будет у одного пакета данных?**\n",
        "\n",
        "Ваш ответ: Размерность одного пакета данных будет [32, 1, 28, 28] для изображений и [32] для меток."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Arv3rg8iK4q1"
      },
      "source": [
        "## Создание модели\n",
        "\n",
        "Ваша задача при инициализации MLP, создать несколько линейных слоев и функцию активации (например ReLU), которые будут использоваться при прямом проходе в модели. Перед входным слоем не забудьте использовать для изображений `.flatten()`. Чтобы вы могли использовать пакеты данных, вам надо подумать какую часть тензора сделать \"плоской\".\n",
        "\n",
        "- Линейный слой `nn.Linear`\n",
        "- Функция активации `nn.ReLU`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "xCsoBNmjK3xP"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "5mZ6znoKRGCF"
      },
      "outputs": [],
      "source": [
        "class MLP(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(MLP, self).__init__()\n",
        "    # Первый линейный слой: 784 входа (28x28 пикселей), 128 выходов\n",
        "    self.fc1 = nn.Linear(784, 128)\n",
        "    # Второй линейный слой: 128 входов, 64 выхода\n",
        "    self.fc2 = nn.Linear(128, 64)\n",
        "    # Третий (выходной) линейный слой: 64 входа, 10 выходов (количество классов в MNIST)\n",
        "    self.fc3 = nn.Linear(64, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # Уплощаем входной тензор x, кроме первого измерения (пакета)\n",
        "    x = x.view(-1, 28*28)  # Или x = x.flatten(start_dim=1)\n",
        "    # Прямой проход через первый слой, затем активация ReLU\n",
        "    x = F.relu(self.fc1(x))\n",
        "    # Прямой проход через второй слой, затем активация ReLU\n",
        "    x = F.relu(self.fc2(x))\n",
        "    # Прямой проход через третий слой (без активации после последнего слоя)\n",
        "    x = self.fc3(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "AthXSoi2Rp-L"
      },
      "outputs": [],
      "source": [
        "# Создание экземпляра класса MLP\n",
        "model = MLP()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Ng4GlzQufHLo"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MLP(\n",
            "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
            "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (fc3): Linear(in_features=64, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "h66fFz8ue1Nu"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([128, 784])\n",
            "torch.Size([128])\n",
            "torch.Size([64, 128])\n",
            "torch.Size([64])\n",
            "torch.Size([10, 64])\n",
            "torch.Size([10])\n"
          ]
        }
      ],
      "source": [
        "for param in model.parameters():\n",
        "  print(param.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKLVRCz9e6MQ"
      },
      "source": [
        "**Сколько параметров в вашей модели?**\n",
        "\n",
        "Ваш ответ:\n",
        "- Входной слой: 784 входа на 128 выходов + 128 смещений\n",
        "params_fc1 = 784 * 128 + 128\n",
        "- Второй слой: 128 входов на 64 выхода + 64 смещения\n",
        "params_fc2 = 128 * 64 + 64\n",
        "- Выходной слой: 64 входа на 10 выходов + 10 смещений\n",
        "params_fc3 = 64 * 10 + 10\n",
        "- Общее количество параметров\n",
        "total_params = params_fc1 + params_fc2 + params_fc3\n",
        "- total_params = 109386\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GtkUPz_K7OO"
      },
      "source": [
        "## Функция потерь и оптимизатор\n",
        "\n",
        "В задаче классификации чаще всего используется функция потерь на основе перекрестной энтропии.\n",
        "\n",
        "В качестве оптимизатора для параметров модели можно выбрать стохастический градиентный спуск или Adam."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "49_C7QmhTE4a"
      },
      "outputs": [],
      "source": [
        "loss_fn = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Luq7PGDSK_yM"
      },
      "outputs": [],
      "source": [
        "from torch.optim import SGD\n",
        "\n",
        "LR = 0.01\n",
        "\n",
        "optimizer = SGD(model.parameters(), lr=LR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScI4FVl2INE7"
      },
      "source": [
        "## Цикл обучения"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "YNmm7GGbISPk"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Эпоха №1\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Потери на обучающей выборке 1.15616\n",
            "Точность на обучающей выборке: 71.16%\n",
            "Потери на обучающей выборке 0.42873\n",
            "Точность на обучающей выборке: 87.80%\n",
            "Эпоха №2\n",
            "Потери на обучающей выборке 0.37495\n",
            "Точность на обучающей выборке: 89.38%\n",
            "Потери на обучающей выборке 0.31813\n",
            "Точность на обучающей выборке: 90.93%\n",
            "Эпоха №3\n",
            "Потери на обучающей выборке 0.30720\n",
            "Точность на обучающей выборке: 91.27%\n",
            "Потери на обучающей выборке 0.27656\n",
            "Точность на обучающей выборке: 92.01%\n",
            "Эпоха №4\n",
            "Потери на обучающей выборке 0.26826\n",
            "Точность на обучающей выборке: 92.40%\n",
            "Потери на обучающей выборке 0.24291\n",
            "Точность на обучающей выборке: 93.18%\n",
            "Эпоха №5\n",
            "Потери на обучающей выборке 0.23734\n",
            "Точность на обучающей выборке: 93.22%\n",
            "Потери на обучающей выборке 0.22032\n",
            "Точность на обучающей выборке: 93.75%\n",
            "Эпоха №6\n",
            "Потери на обучающей выборке 0.21056\n",
            "Точность на обучающей выборке: 94.09%\n",
            "Потери на обучающей выборке 0.19576\n",
            "Точность на обучающей выборке: 94.30%\n",
            "Эпоха №7\n",
            "Потери на обучающей выборке 0.18836\n",
            "Точность на обучающей выборке: 94.56%\n",
            "Потери на обучающей выборке 0.17651\n",
            "Точность на обучающей выборке: 94.86%\n",
            "Эпоха №8\n",
            "Потери на обучающей выборке 0.16949\n",
            "Точность на обучающей выборке: 95.16%\n",
            "Потери на обучающей выборке 0.16336\n",
            "Точность на обучающей выборке: 95.13%\n",
            "Эпоха №9\n",
            "Потери на обучающей выборке 0.15373\n",
            "Точность на обучающей выборке: 95.60%\n",
            "Потери на обучающей выборке 0.14642\n",
            "Точность на обучающей выборке: 95.62%\n",
            "Эпоха №10\n",
            "Потери на обучающей выборке 0.14022\n",
            "Точность на обучающей выборке: 95.98%\n",
            "Потери на обучающей выборке 0.13662\n",
            "Точность на обучающей выборке: 95.88%\n"
          ]
        }
      ],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "n_epochs = 10\n",
        "\n",
        "best_acc = 0\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "  train_loss = 0\n",
        "  train_correct = 0\n",
        "  test_loss = 0\n",
        "  test_correct = 0\n",
        "  print(f\"Эпоха №{epoch+1}\")\n",
        "  model.train() # переключение модели в режим обучения\n",
        "  for imgs, labels in train_loader:\n",
        "    optimizer.zero_grad()  # Обнуляем градиенты\n",
        "    outputs = model(imgs)  # Получаем вывод модели\n",
        "    loss = loss_fn(outputs, labels)  # Вычисляем потери\n",
        "    loss.backward()  # Вычисляем градиенты\n",
        "    optimizer.step()  # Обновляем параметры\n",
        "\n",
        "    train_loss += loss.item()\n",
        "    train_correct += (outputs.argmax(1) == labels).sum().item()\n",
        "\n",
        "  avg_train_loss = train_loss / len(train_loader)\n",
        "  train_acc = train_correct / len(train_loader.dataset)\n",
        "  print(f\"Потери на обучающей выборке {avg_train_loss:.5f}\")\n",
        "  print(f\"Точность на обучающей выборке: {train_acc*100:.2f}%\")\n",
        "\n",
        "  model.eval() # переключение модели в режим оценивания\n",
        "  for imgs, labels in test_loader:\n",
        "    with torch.no_grad(): # работа в контексте отключенного вычисления градиентов\n",
        "      outputs = model(imgs)\n",
        "      loss = loss_fn(outputs, labels)\n",
        "\n",
        "      test_loss += loss.item()\n",
        "      test_correct += (outputs.argmax(1) == labels).sum().item()\n",
        "\n",
        "  avg_test_loss = test_loss / len(test_loader)\n",
        "  test_acc = test_correct / len(test_loader.dataset)\n",
        "  print(f\"Потери на обучающей выборке {avg_test_loss:.5f}\")\n",
        "  print(f\"Точность на обучающей выборке: {test_acc*100:.2f}%\")\n",
        "\n",
        "  if test_acc > best_acc:\n",
        "    best_acc = test_acc\n",
        "    torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            }, \"best_model_params.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIpCgKmSq2kl"
      },
      "source": [
        "**Почему для оценки модели стоит отключать вычисление градиентов `with torch.no_grad()`?**\n",
        "\n",
        "Ваш ответ: экономия ресурсов, предотвращение изменения в модели, корректная оценка модели"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHpTqJ_yIJAo"
      },
      "source": [
        "## Загрузка модели и инференс\n",
        "\n",
        "Ранее были оптимизированы параметры модели и словарь с параметрами для лучшей точности на проверочной выборке был сохранен в виде файла.\n",
        "\n",
        "Модель обучается для ее использования с реальными данными, что и будет сделано в этой части задания.\n",
        "\n",
        "Для этого вам потребуется нарисовать цифру в любом графическом редакторе (Paint, Gimp, Photoshop).\n",
        "\n",
        "Требования к изображению происходят из тех данных, на которых обучалась модель. Поэтому изображение должно быть черно-белое, ширина и высота 28 px, черный фон, белая цифра. Формат может быть как png, так и jpg.\n",
        "\n",
        "Для загрузки изображения в Google Colab в боковой панели откройте Files (1), и выберите вариант Upload to session storage (2).\n",
        "\n",
        "Затем файл необходимо считать и подготовить перед тем, как передать в модель.\n",
        "\n",
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "BEvcMIyFCOUn"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ширина и высота (28, 28), количество каналов 1\n"
          ]
        },
        {
          "data": {
            "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAcABwBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APn+vUPDnwR1rWdGg1S/1Gy0i3uAGgW5J3uD0OOMZ+ua53xx8PNZ8CXMK6h5U1tcZ8m6gJKOR1HPIPtXI09G2Or4DbSDg9DXo0t74m+Nmv21in2G2ksrUlIgzRxBQwBOOeeR+Arrvi7C/hn4WeGfCl7K11fxuHa4CNsAUMMBj/vAY64FeEU+PZ5i+ZnZkbsdcd8V7B4k+DN0tppuqeApJ9TsbqEM5M6BwTyDngYx27EVq/ExJ9A+Cvh/w/r1wk+uGYOAX3sijdnnvgMq5rweitrR/F/iLQIzFpOs3lpExyY4pSFz9OlUdR1S/wBXvGu9RvJ7u4bGZJnLN+ZqnX//2Q==",
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAB+klEQVR4AWVSPWgUQRT+Zt7snmfiGQ3qHRIInlioiKIoWlqorYhWdoqVBGwkpXV6sRGsbLQRxEJEQbHRAyGeJIhwQVBUCJwa1uR2d+b53u4dG+PHMrPzfr5573sDVLCwcAYkFmsqsx5hIiDWL5bD/xDbJoK1kvuvm4gsIrGp2ZW067n3nGw31xYXOlmUbmC1Yze7nDPz8p3d4tKqKkRzq4F5wIHD49YGH86vMPfu3374OWQ8O8qU1qQL1B4xd49HcPtfe+5ODos1UhKBDn9jf7mmdFc5/XlMwgWOycN6b/vh99uBSvM9i6QdLpzwFDLg0+ldrhenHmgBKz9qEicgCLFyK1x9/FyHw9NIlNSjBxsKDPKRb9xqt6Z2on8vG2kjeRJntb5tC9prNivSuyK1rEt4xTvxMvnlPS+dKT26FnbhMdYcOHJqZilwZ/uwz2KzrhhGMciLOScXSmltgIwv5HFj+lCcIhg3/xWbG2WmBQUvNR19/uLBXsTE+Ro8G+lcoLqKHJba0/uu1UUEc6JJyaK+lwJGOcZeBV6+0axPnv3g/bsdwz6LqynGlT+ek/dP3sjk0uuQJzNK1IDaXJKx55BzuLtFH+l60PilZ/0shNWPM1uJyjtHIkocTUwdbA56819kYMXEqtxIw6Q2pwvKqVTe8k/61onrCvwFqiSs8KqaLPUAAAAASUVORK5CYII=",
            "text/plain": [
              "<PIL.JpegImagePlugin.JpegImageFile image mode=L size=28x28>"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from PIL import Image\n",
        "img = Image.open('photo/3new.jpg')\n",
        "print(f\"Ширина и высота {img.size}, количество каналов {len(img.mode)}\")\n",
        "img"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mXtI0hzKZoK"
      },
      "source": [
        "**Соответствует ли изображение требованиям?**\n",
        "\n",
        "Ваш ответ: нет\n",
        "\n",
        "\n",
        "Если количество каналов у вас больше одного, то код далее поможет это исправить."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "ywx9wLJrLrVo"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 28, 28])\n"
          ]
        }
      ],
      "source": [
        "import torchvision.transforms as transforms\n",
        "# Раскомментируйте, если у вас цветное изображение\n",
        "transform_grayscale = transforms.Grayscale()\n",
        "img = transform_grayscale(img)\n",
        "\n",
        "# Используем те же преобразования как и при создании датасетов в начале задания\n",
        "transform_to_tensor = transforms.ToTensor()\n",
        "x = transform_to_tensor(img)\n",
        "\n",
        "# Вывод размерностей тензора x\n",
        "print(x.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIFcW_g2ND1g"
      },
      "source": [
        "Но работа нашей модели строилась с учетом использования пакетов данных (batches), которые создавали экземпляры класса DataLoader, поэтому для использования одного изображения нам надо имитировать пакет из одного изображения. С этим поможет метод тензора `unsqueeze`, а чтобы не создавать отдельную переменную можно воспользоваться методом `unsqueeze_`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "hru4DrGZMV8Q"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Размерность тензора x после unsqueeze: torch.Size([1, 1, 28, 28])\n"
          ]
        }
      ],
      "source": [
        "# Имитация пакета из одного изображения\n",
        "x.unsqueeze_(0)  # Добавляет дополнительное измерение\n",
        "\n",
        "# Вывод размерности модифицированного тензора x\n",
        "print(f\"Размерность тензора x после unsqueeze: {x.size()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htgOurpsOVgs"
      },
      "source": [
        "Изображение подготовлено, теперь необходимо воссоздать модель и загрузить в нее параметры, которые дали наилучший результат при обучении."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "oZP1H5VwOMO3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "MLP(\n",
              "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
              "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (fc3): Linear(in_features=64, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_model = MLP()\n",
        "best_model_params = torch.load('best_model_params.pth') # Укажите путь до сохраненного файла\n",
        "state_dict = best_model_params['model_state_dict'] # Из best_model_params извлеките по соответствующему ключу параметры модели\n",
        "# Загрузка параметров в модель\n",
        "best_model.load_state_dict(state_dict)\n",
        "\n",
        "# Переключение модели в режим проверки\n",
        "best_model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aN2s_oNuQDzQ"
      },
      "source": [
        "Осталось воспользоваться моделью. Передайте на вход модели подготовленный тензор. Из вывода модели получите индекс наибольшего значения (`argmax`) и по индексу получите результат из массива ярлыков классов (`test_set.classes`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "OZbLYZvDRd5_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Предсказанный класс: 3 - three\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():  # Отключаем вычисление градиентов\n",
        "    output = best_model(x)  # Передаем тензор через модель\n",
        "\n",
        "# Получаем индекс наибольшего значения в выводе модели\n",
        "predicted_index = torch.argmax(output, dim=1).item()\n",
        "\n",
        "# Используем индекс для получения названия класса\n",
        "predicted_class = test_set.classes[predicted_index]\n",
        "\n",
        "print(f\"Предсказанный класс: {predicted_class}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7A0E5_D4RgFU"
      },
      "source": [
        "**Правильно ли предсказала модель цифру?**\n",
        "\n",
        "Ваш ответ: да\n",
        "\n",
        "**Лучшая точность на тестовой выборке для вашей модели.**\n",
        "\n",
        "Ваш ответ: 95.63%\n",
        "\n",
        "**Что такое пакет данных (batch)?**\n",
        "\n",
        "Ваш ответ: \n",
        "Пакет данных (batch) — это набор образцов данных, используемый при обучении нейронной сети, который обрабатывается за один проход алгоритма обучения. Вместо обучения модели на одном образце за раз (что может быть неэффективно и медленно) или на всем наборе данных сразу (что может требовать слишком много памяти), данные разбиваются на меньшие пакеты.\n",
        "\n",
        "**В чем заключается смысл стохастического градиентного спуска?**\n",
        "\n",
        "Ваш ответ: Стохастический градиентный спуск (Stochastic Gradient Descent, SGD) — это итеративный метод оптимизации, используемый для минимизации функции потерь при обучении машинных моделей, в частности, нейронных сетей. В отличие от классического градиентного спуска, который вычисляет градиент функции потерь на всем тренировочном наборе данных (что может быть вычислительно затратно для больших данных), SGD обновляет веса модели, используя градиент, вычисленный на основе одного случайно выбранного образца или небольшого пакета образцов."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
